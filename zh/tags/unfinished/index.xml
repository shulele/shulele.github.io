<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Unfinished on </title>
    <link>/zh/tags/unfinished/</link>
    <description>Recent content in Unfinished on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-Hans</language>
    <lastBuildDate>Tue, 16 Apr 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/zh/tags/unfinished/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>The explanation of Bayesian Theorem in Statistics</title>
      <link>/zh/post/the-explanation-of-bayesian-theorem-in-statistics/</link>
      <pubDate>Tue, 16 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/zh/post/the-explanation-of-bayesian-theorem-in-statistics/</guid>
      <description>Bayesian probability Inference Educated guessing
Thomas Bayes A nonconformist; two books, about theology and probability.
Bayesian inference Guessing the probability in the style of Bayes
Bayesian probability also known as evidential probability, is the process of adding prior probability to a hypothesis and adjusting that probability as new information becomes available. Unlike traditional frequentist probability which only accounts for the previous frequency of an event to predicate and outcome, the Bayesian model begins with an initial set of subjective assumptions (prior probability) and adjusts them accordingly through trial and experimentation (posterior probability).</description>
    </item>
    
  </channel>
</rss>